{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification is a process of categorizing a given set of data into classes, It can be performed both structure or unstructure \\ndata. The process start with predicting the class of given data points. The classes are often reffer to as target, label or\\ncategorizes. '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''classification is a process of categorizing a given set of data into classes, It can be performed both structure or unstructure \n",
    "data. The process start with predicting the class of given data points. The classes are often reffer to as target, label or\n",
    "categorizes. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification terminology\n",
    "# classifier>classification model> feature> binary>multiclass> multilevel> initailize> train> predict> evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types of learner\n",
    "#Lazy learner: simply store in training data and wait until a testing data appears e.g KNN\n",
    "#eager learner: construct a classification model based on the driven training data before getting data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification evaluation: Hold Out Method, classificaiton report, ROC curve, cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out method: two split data into two parts(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation : split data into k number of fold (it uses to remove the overfitting problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report: accuracy, precision, recall, F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit classification uses MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=mnist['data'], mnist['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15adf4e0c70>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_digit=X[13]\n",
    "img=random_digit.reshape(28,28)\n",
    "plt.imshow(img, cmap=matplotlib.cm.binary, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test=X[:6000], X[6000:7000]\n",
    "y_train,y_test=y[:6000], y[6000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index=np.random.permutation(6000)\n",
    "x_train,y_train=x_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype(np.int8)\n",
    "y_test=y_test.astype(np.int8)\n",
    "y_train_2=(y_train==2)\n",
    "y_test_2=(y_test==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True,  True,  True, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= LogisticRegression(tol= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(tol=0.1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict([random_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
